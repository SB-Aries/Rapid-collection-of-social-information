一款基于 Python Tkinter 开发的可视化工具，支持单 URL / 批量 URL 爬取网页中的邮箱和中国手机号，全程自动去重，操作简单、结果可直接保存。
📌 功能特点

功能	说明
🖥️ 可视化 GUI	无需命令行操作，全图形界面交互，新手友好
📝 双爬取模式	支持「单 URL 爬取」和「批量 URL 爬取（从 TXT 读取）」
🧹 全流程去重	自动去重 URL 列表、单 URL 内数据、多 URL 间全局数据，最终仅保留唯一结果
📱 手机号适配	支持提取多种格式的中国手机号（含 + 86、空格、- 分隔、纯 11 位），自动清洗为纯 11 位数字
📧 邮箱提取	兼容主流邮箱格式，精准提取并去重
💾 结果保存	爬取结果自动排序后保存为 TXT 文件，目录清晰
🌐 网络检测	启动爬取前自动检查网络连接，避免无效操作
📦 自动装依赖	检测到缺失requests库时自动安装，无需手动配置
🛠️ 环境要求

Python 版本：Python 3.6 及以上（推荐 3.8+）
系统兼容：Windows / Linux /macOS（全平台支持）
依赖库：仅需requests（代码会自动检测并安装，无需手动操作）
🚀 使用步骤

1. 运行代码

将代码保存为web_scraper.py，直接运行：
bash


运行




python web_scraper.py
首次运行若缺失requests库，工具会自动弹出提示并安装，等待即可。
运行后会打开可视化操作窗口。
2. 选择爬取模式

模式 1：单 URL 爬取

选择「单 URL 爬取」单选框；
在「输入内容」框中填写完整 URL（必须带http://或https://，例：https://www.example.com）；
勾选需要爬取的内容（邮箱 / 中国手机号，至少勾选一项）；
点击「开始爬取」，等待爬取完成。
模式 2：批量 URL 爬取

准备 URL 列表 TXT 文件：
新建 TXT 文件（如urls.txt）；
每行填写一个完整 URL，示例：
txt





https://www.example1.com
https://www.example2.com
https://www.example3.com
选择「批量 URL 爬取（从 TXT 读取）」单选框；
点击「选择 TXT 文件（每行一个 URL）」，选中准备好的 TXT 文件；
勾选需要爬取的内容（邮箱 / 中国手机号，至少勾选一项）；
点击「开始爬取」，工具会自动遍历所有 URL 并爬取，实时显示进度和结果。
3. 结果操作

查看结果：爬取过程和结果会实时显示在「爬取结果」文本框中，不同颜色标识状态（蓝色 = 提示、绿色 = 成功、红色 = 错误）；
手动去重（可选）：点击「手动去重结果」可强制兜底去重，并显示去重前后数据量对比；
保存结果：爬取完成后点击「保存结果」，选择保存目录，工具会自动创建web_scraper_results_deduplicated文件夹，生成：
unique_emails.txt：去重并排序后的邮箱列表；
unique_china_phones.txt：去重并排序后的中国手机号列表；
清空结果：点击「清空结果」可重置所有爬取数据和日志。
⚠️ 注意事项

URL 格式要求：必须填写完整 URL（含http:///https://），否则会提示「URL 格式无效」；
网络要求：爬取前确保网络正常，工具会自动检测网络（访问百度验证）；
反爬提示：工具已添加浏览器User-Agent模拟正常访问，但部分网站可能有反爬机制，导致爬取失败或结果为空；
数据合法性：本工具仅用于学习和合法场景，禁止爬取非公开 / 侵权数据，违者后果自负；
手机号清洗：提取的手机号会自动清洗为纯 11 位数字（例：+86 138-1234-5678 → 13812345678）；
批量 TXT 格式：TXT 文件需 UTF-8 编码，每行仅一个 URL，空行会自动过滤。
❓ 常见问题

Q1：爬取失败 / 提示「爬取 xxx 失败」？

检查目标 URL 是否可正常访问；
确认网络连接正常；
目标网站可能有反爬策略（如 IP 限制、验证机制），可更换网络或稍后再试；
URL 格式是否正确（必须带http:///https://）。
Q2：爬取结果为空？

目标网页本身无邮箱 / 手机号数据；
网页内容为动态加载（工具仅爬取静态 HTML，无法提取 JS 动态渲染的内容）；
手机号 / 邮箱格式超出正则匹配范围（可微调代码中的正则表达式适配特殊格式）。
Q3：保存结果后文件为空？

爬取过程中未提取到有效数据，可检查爬取日志确认；
未勾选对应的爬取选项（邮箱 / 手机号）。
📄 许可证

本项目仅用于学习交流，请勿用于商业或非法用途。使用本工具即表示您同意遵守相关法律法规。
